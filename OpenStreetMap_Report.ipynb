{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Denver Metropolitan Area, Colorado, USA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to work on the Open Street Map data for my hometown, Boulder, Colorado and it's surrounding area, including the state capital of Denver.\n",
    "\n",
    "https://mapzen.com/data/metro-extracts/metro/denver-boulder_colorado/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Auditing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first field I looked at was the Street Name field, continuing with the code from one of the class exercises. From the audit, I created a full list of acceptable street names, as well as a mapping from abbreviations and other forms of the name that I saw in the data to these acceptable forms. Unlike in the exercise, I modified the code to apply the mapping to each word in the street name, to account for values like 'County Rd 126' which should be 'Country Road 126'. I also included some typos that I noticed while auditing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Broadway\", \"Drive\", \"Center\", \"Circle\", \"Commons\", \"Court\", \"Highway\",\n",
    "            \"Place\", \"Square\", \"Lane\", \"Loop\", \"Mall\", \"Road\", \"Trail\", \"Parkway\", \"Place\", \"Point\", \"Ramp\", \"Way\",\n",
    "            \"Terrace\", \"Plaza\", \"Crescent\"]\n",
    "\n",
    "mapping = { \"St\": \"Street\", \"st\": \"Street\", \"Strret\": \"Street\", \"STreet\": \"Street\",\n",
    "            \"Ave\": \"Avenue\", \"ave\": \"Avenue\", \"Av\": \"Avenue\",\n",
    "            \"Blvd\": 'Boulevard',\n",
    "            \"Ct\": \"Court\", \"ct\": \"Court\",\n",
    "            \"Cir\": \"Circle\", \"circle\": \"Circle\",\n",
    "            \"Dr\": \"Drive\", \"drive\": \"Drive\",\n",
    "            \"Hwy\": \"Highway\",\n",
    "            \"Pkwy\": \"Parkway\", \"Pky\": \"Parkway\",\n",
    "            \"Pl\": \"Place\",\n",
    "            \"Rd\": \"Road\", \"rd\": \"Road\", \"Raod\": \"Road\",\n",
    "            \"SH\": 'State Highway',\n",
    "            \"SR\": \"State Road\",\n",
    "            \"E\": \"East\", \"W\": \"West\", \"S\": \"South\", \"N\": \"North\",\n",
    "            \"Main\": \"Main Street\", \"Mainstreet\": \"Main Street\",\n",
    "            \"US\": \"US Highway\",\n",
    "            \"Co\": \"Colorado\", \"CO\": \"Colorado\",\n",
    "            \"lane\": \"Lane\", \"Ln\": \"Lane\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also manually corrected for some errors that I knew about from living in the area. For example, I know that Broadway does not have a street type like Avenue or Boulevard, that Baseline should be Baseline Road, and that East Colfax should be East Colfax Avenue. I confirmed all of these using Google Maps, just in case. \n",
    "\n",
    "I also noticed several street names included suite or unit numbers, which I removed.\n",
    "\n",
    "The cleaning function ended up like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_st_name(name, mapping):\n",
    "\n",
    "    name = name.replace('.', '')\n",
    "    name = name.replace(',', '')\n",
    "    name = name.replace('-', ' ')\n",
    "\n",
    "    if 'Baselin' in name:\n",
    "        return 'Baseline Road'\n",
    "\n",
    "    if name == 'East Colfax':\n",
    "        return 'East Colfax Avenue'\n",
    "\n",
    "    name = name.split(' ')\n",
    "    for i, name_word in enumerate(name):\n",
    "\n",
    "        if any(unit == name_word for unit in ['Suite', 'suite', 'ste', 'Ste', 'Suit', 'Unit', 'unit']) \\\n",
    "                or '#' in name_word:\n",
    "            name = name[:i]\n",
    "\n",
    "        if name_word in mapping.keys():\n",
    "            # print name\n",
    "            name[i] = mapping[name_word]\n",
    "\n",
    "    name = ' '.join(name)\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still several problems remaining in the data. There are several street names without the street type (e.g. 'Lincoln') which could be referring to a number of actual streets. These would need to be fixed by comparing the location with a trusted source. Otherwise, most of the problems seem to stem from the data being entered into the wrong field. For example, there are several four-digit numbers, which are most likely address numbers. There are also several full addresses in this field. These can be fixed on a case-by-case basis for this particular dataset, but should be done programmatically for larger ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next field I looked at was zipcodes. This was considerably simpler, as most of the data was entered correctly. I simply wrote a function that would check if a zipcode was valid (5-digit number between 80000 and 80700). To get everything to match, I had to convert some from the 9-digit version and remove the state abbreviation from a few others. This left a few values that were in the wrong field, as in the street name case. I also noticed three 6 digit numbers that looked like valid zipcodes with an extra digit (802377, 801111 and 801112). Although it is difficult to know which digit should be removed, I simply used the first 5 digits. \n",
    "\n",
    "I would suggest checking all the zipcodes against their latitude and longitude after the data is in the database. This would correct any human error in the inputting process, as well as correct my error if this assumption was wrong. However, this information may not be readily available or accessible. Ideally, there would be a free service with worldwide zipcode information including what latitude and longitude coordinates they covered. With a little searching, I have found http://federalgovernmentzipcodes.us/, which seems to do the trick for United States zipcodes, and there seem to be other country-specific ones. The above link notes that their data is accurate to two decimal places of latitude and longitude, which means a margin of error of around half a mile. Since this data is on the level of individual addresses, this could pose some problems on the borders of zipcodes.\n",
    "\n",
    "The cleaning functions looked like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_valid_zip(zip):\n",
    "    return len(zip) == 5 and str.isdigit(zip) and int(zip) in range(80000, 80700)\n",
    "\n",
    "\n",
    "def update_zip(zip):\n",
    "\n",
    "    if '-' in zip:\n",
    "        zip = zip.split('-')\n",
    "        zip = zip[0]\n",
    "    elif ' ' in zip:\n",
    "        zip = zip.split(' ')\n",
    "        zip = zip[-1]\n",
    "    elif 'CO' in zip:   # for format 'CO88888'\n",
    "        zip = zip[2:]\n",
    "\n",
    "    if is_valid_zip(zip):\n",
    "        return zip\n",
    "    elif is_valid_zip(zip[:-1]):\n",
    "        return zip[:-1]\n",
    "    else:\n",
    "        return 'NULL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I audited the city, county, state, and country fields with the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit(osmfile, field):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    count = {}\n",
    "\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == 'node' or elem.tag == 'way':\n",
    "            for tag in elem.iter('tag'):\n",
    "                if tag.attrib['k'] == field:\n",
    "                    v = tag.attrib['v']\n",
    "                    if v in count.keys():\n",
    "                        count[v] += 1\n",
    "                    else:\n",
    "                        count[v] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The county and country audits showed that all values were in the same format, so nothing to do there.\n",
    "\n",
    "For state, there were a few different formats, but everything was in the state of Colorado, so I simply changed everything to that.\n",
    "\n",
    "I noticed a few problems in the city field. Several values, included the state, so I removed that. I also made a mapping of some typos that I noticed in the audit to the correct city names. Finally, I capitalized the first letter of each field.\n",
    "\n",
    "Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_state(state):\n",
    "    return 'Colorado'\n",
    "\n",
    "\n",
    "city_typos = {'Auroraa': 'Aurora',\n",
    "              'CONIFER': 'Conifer',\n",
    "              'Centenn': 'Centennial',\n",
    "              'Dener': 'Denver',\n",
    "              'ENGLEWOOD': 'Englewood',\n",
    "              'Edgwater': 'Edgewater',\n",
    "              'Hemderson': 'Henderson',\n",
    "              'Littleton co': 'Littleton',\n",
    "              'PARKER': 'Parker',\n",
    "              'Thorton': 'Thornton',\n",
    "              'Westminister': 'Westminster',\n",
    "              'WestminsterO': 'Westminster',\n",
    "              '+' : 'NULL',\n",
    "              'CO': 'NULL',\n",
    "              'CO 80129' : 'NULL'}\n",
    "\n",
    "def update_city(city):\n",
    "    city = city[0].upper() + city[1:]\n",
    "    if ', CO' in city:\n",
    "        city = city.split(',')[0]\n",
    "    if city in city_typos.keys():\n",
    "        city = city_typos[city]\n",
    "    return city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To my knowledge, there are no more errors in these fields. However, they are missing from many of the entries, so a further step may be to add the correct values based on the latitude and longitude data. This can be done once the data is in the SQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import to SQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the schema and modified code from the class exercise to convert the XML data into python dictionaries, while applying my cleaning functions along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    if element.tag == 'way':\n",
    "        for field in way_attr_fields:\n",
    "            way_attribs[field] = element.attrib[field]\n",
    "\n",
    "        pos_counter = 0\n",
    "        for node in element.iter('nd'):\n",
    "            node_dict = {}\n",
    "\n",
    "            node_dict['id'] = element.attrib['id']\n",
    "            node_dict['node_id'] = node.attrib['ref']\n",
    "            node_dict['position'] = pos_counter\n",
    "\n",
    "            pos_counter += 1\n",
    "            way_nodes.append(node_dict)\n",
    "\n",
    "    elif element.tag == 'node':\n",
    "        for field in node_attr_fields:\n",
    "            node_attribs[field] = element.attrib[field]\n",
    "\n",
    "    for tag in element.iter('tag'):\n",
    "        if not problem_chars.search(tag.attrib['k']):\n",
    "            tag_dict = {}\n",
    "            tag_dict['id'] = element.attrib['id']\n",
    "\n",
    "            #change fields that I cleaned\n",
    "            if tag.attrib['k'] == 'addr:street':\n",
    "                tag_dict['value'] = update_st_name(tag.attrib['v'], mapping)\n",
    "            elif tag.attrib['k'] == 'addr:state':\n",
    "                tag_dict['value'] = update_state(tag.attrib['v'])\n",
    "            elif tag.attrib['k'] == 'addr:postcode':\n",
    "                tag_dict['value'] = update_zip(tag.attrib['v'])\n",
    "            elif tag.attrib['k'] == 'addr:city':\n",
    "                tag_dict['value'] = update_city(tag.attrib['v'])\n",
    "            else:\n",
    "                tag_dict['value'] = tag.attrib['v']\n",
    "\n",
    "            if ':' not in tag.attrib['k']:\n",
    "                tag_dict['key'] = tag.attrib['k']\n",
    "                tag_dict['type'] = default_tag_type\n",
    "            else:\n",
    "                k = tag.attrib['k'].split(':')\n",
    "                tag_dict['type'] = k[0]\n",
    "                tag_dict['key'] = ':'.join(k[1:])\n",
    "\n",
    "            tags.append(tag_dict)\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting csv files were then imported into a sqlite database for the following queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "denver-boulder_colorado.osm - 825.4 MB   \n",
    "osm_denver_boulder.db - 58.9 MB   \n",
    "nodes.csv - 31.9 MB   \n",
    "nodes_tags.csv - 1.1 MB    \n",
    "ways.csv - 2.6 MB    \n",
    "ways_nodes.csv - 10.3 MB   \n",
    "ways_tags.csv - 6.1 MB   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY = 'SELECT COUNT(DISTINCT(s.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) as s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1334"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY = 'SELECT COUNT(*) FROM nodes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "372635"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY = 'SELECT COUNT(*) FROM ways'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Ten Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY = 'SELECT value, COUNT(*) as n FROM node_tags WHERE key = \"amenity\" GROUP BY value ORDER BY n DESC LIMIT 10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* restaurant 181 \n",
    "* fast_food 90\n",
    "* bicycle_parking 76\n",
    "* bench 72\n",
    "* place_of_worship 69\n",
    "* school 66\n",
    "* fuel 59\n",
    "* parking 47\n",
    "* cafe 34\n",
    "* toilets 34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Ten Restaurant Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY = 'SELECT value, COUNT(*) as n FROM node_tags WHERE key = \"cuisine\" GROUP BY value ORDER BY n DESC LIMIT 10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sandwich 25\n",
    "* mexican 22\n",
    "* pizza 20\n",
    "* burger 19\n",
    "* american 18\n",
    "* coffee_shop 13\n",
    "* asian 8\n",
    "* ice_cream 5\n",
    "* italian 5\n",
    "* chinese 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Five Religious Denominations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "QUERY = 'SELECT value, COUNT(*) as n FROM node_tags WHERE key = \"denomination\" GROUP BY value ORDER BY n DESC LIMIT 5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* lutheran 10\n",
    "* methodist 7\n",
    "* baptist 5\n",
    "* catholic 4\n",
    "* episcopal 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there more coffee shops or marijuana dispensaries in the Denver area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY = 'SELECT COUNT(*) FROM node_tags WHERE (key = \"amenity\" AND value = \"cafe\") \\\n",
    "OR (key = \"cuisine\" AND value = \"coffee_shop\")'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of cafes/coffee shops: 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY = 'SELECT COUNT(*) FROM node_tags WHERE key = \"amenity\" AND value = \"dispensary\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of dispensaries: 0 (clearly, the data is incomplete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there is still plenty to be done with this dataset, I have standardized the addresses to make them significantly more readable and correct. Similar cleaning could be done to make the categorizations more useful (for example, amenity-restaurant-coffee shop and amenity-cafe are the same thing), and it would be good to verify the correctness of the data by checking the latitude and longitude against a trusted source and confirming that the full address information is accurate. From there, what remains is to add more data to get a complete map of the area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "https://discussions.udacity.com/t/creating-db-file-from-csv-files-with-non-ascii-unicode-characters/174958/7  \n",
    "https://discussions.udacity.com/t/last-quiz-preparing-for-database-in-lesson-6-mongodb/44559/30  \n",
    "http://sebastianraschka.com/Articles/2014_sqlite_in_python_tutorial.html#connecting-to-an-sqlite-database  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
